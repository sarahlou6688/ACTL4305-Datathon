#1. DATA PREP ----

#load packages
library(data.table)
library(lubridate)
library(ggplot2)
library(ggcorrplot)
library(dplyr)
library(tidyverse)
library(glmnet)
library(caret)
library(e1071)
library(randomForest)
library(PRROC) 
library(doParallel)
library(Rcpp)
library(statmod)
library(MLmetrics)
library(MASS)


#import data 
claims_data_raw   = read.csv("UNSW_claims_data.csv", header = TRUE)
earned_data_raw   = read.csv("UNSW_earned_data_adjusted_Sep27.csv", header = TRUE)
new_customer_data = read.csv("New_Customers_Pricing_Output_File.csv", header = TRUE)

#CLAIMS DATA ----
claims_data      = setDT(claims_data_raw)

# summary(claims_data$total_claim_amount) 
# summary(claims_data$claim_paid) 
# summary(claims_data$tenure) #contains negative tenure values which doesn't make sense 
# unique(claims_data$claim_status) #why is there covered and covered_with_exclusions? should just be split between paid and not paid? 
# unique(claims_data$condition_category)
# length(unique(claims_data$claim_id)) #less than number of rows in data so duplicates
# length(unique(claims_data$exposure_id))

#remove time from claim_start_date and turn class into DATE
claims_data[, claim_start_date := lubridate::ymd(substr(claim_start_date, 1, 10))]

#change negative tenure values to 0
claims_data = claims_data[tenure < 0, tenure := 0]

#change column classes 
claims_data[, condition_category := as.factor(condition_category)]

#each row contains a single claim 
claims_data[, claim_count := 1]

#check for duplicate claim_id 
# View(claims_data[duplicated(claims_data$claim_id)])

#aggregate on a claim_id level
claims_data_new = claims_data[,  .(total_claim_amount = sum(total_claim_amount), 
                                   claim_paid         = sum(claim_paid), 
                                   claim_count        = sum(claim_count)), 
                                 .(claim_id,
                                   exposure_id,
                                   claim_start_date, 
                                   claim_status, 
                                   condition_category, 
                                   tenure)]
# View(claims_data_new[duplicated(claims_data_new$claim_id)])
# nrow(claims_data_new) - length(unique(claims_data_new$claim_id)) #this isnt zero due to rows where claim_id is identical but other columns are different eg. condition_category which we cant aggregate


#EARNED DATA ----
#Dataset view
earned = earned_data_raw
dim(earned)
summary(earned)

# Remove duplicate rows from 'earned' dataset
earned <- earned %>% distinct() #none detected

# Convert into correct data type
earned$pet_gender <- factor(earned$pet_gender)
earned$nb_address_type_adj <- factor(earned$nb_address_type_adj)
earned$nb_state <- factor(earned$nb_state)
earned$pet_de_sexed <- as.logical(earned$pet_de_sexed)
earned$pet_is_switcher <- as.logical(earned$pet_is_switcher)
earned$is_multi_pet_plan <- as.logical(earned$is_multi_pet_plan)

#UW_data make the month
#Extract the month as a name using `month()` from `lubridate` and `factor()`
earned$UW_Date_month <- month(earned$UW_Date)

# Convert the numeric month to a full month name using `base` R's `month.name` vector
earned$UW_Date_month <- factor(month.name[earned$UW_Date_month], levels = month.name)


# Convert 'nb_policy_first_inception_date' to date format without the time
earned$nb_policy_first_inception_date <- as_date(earned$nb_policy_first_inception_date)

# Remove specified columns from the 'earned' dataset
earned <- subset(earned, select = -c(quote_date, quote_time_group, lead_date_day, person_dob, pet_age_years, UW_Date, row_num, exposure_id_1))

#Check for NA values present in the dataset
na_summary_freq<-sapply(earned, function (x) sum(is.na(x)))
na_summary_freq

unique(earned$pet_is_switcher)
unique(earned$pet_de_sexed_age)

# Remove the 'tenure' column using subset
earned <- subset(earned, select = -tenure)

# Group by exposure_id and sum earned_units
earned_sum <- earned %>%
  group_by(exposure_id) %>%
  summarise(earned_units = sum(earned_units, na.rm = TRUE), .groups = "drop")

# Get the first occurrence of each exposure_id to keep other columns intact
earned_unique <- earned %>%
  distinct(exposure_id, .keep_all = TRUE)

# Remove the original earned_units column to avoid duplication
earned_unique <- earned_unique[, !(names(earned_unique) %in% "earned_units")]

# Join the summed earned_units with the unique dataset
earned <- left_join(earned_unique, earned_sum, by = "exposure_id")

# Display the first few rows to check the result
head(earned)

####Not Sure Cleaning
age_frequency <- earned %>%
  group_by(nb_breed_name_unique, pet_de_sexed_age) %>%
  summarise(age_frequency = n(), .groups = 'drop') %>%
  arrange(nb_breed_name_unique, pet_de_sexed_age)

print(age_frequency)

breed_mode <- age_frequency %>%
  group_by(nb_breed_name_unique) %>%
  slice_max(age_frequency, with_ties = FALSE)  # Keep the row with the highest frequency

# View the result
print(breed_mode)

#replace not sure wtih mode
earned <- earned %>%
  left_join(breed_mode, by = "nb_breed_name_unique", suffix = c("", "_mode"))

# Replace "Not Sure" with the mode from breed_mode
earned <- earned %>%
  mutate(pet_de_sexed_age = ifelse(pet_de_sexed_age == "Not Sure", 
                                   pet_de_sexed_age_mode,  # Use the mode from breed_mode
                                   pet_de_sexed_age))      # Keep the original value otherwise

# Drop the extra mode column if not needed
earned <- earned %>%
  dplyr::select(-pet_de_sexed_age_mode)

#Randomise Values for not sure
set.seed(1060)
# Filter out "Not Sure" values and get unique values from the pet_de_sexed_age column
valid_values <- earned$pet_de_sexed_age[earned$pet_de_sexed_age != "Not Sure"]

# Randomly replace "Not Sure" with any of the valid values
earned <- earned %>%
  mutate(pet_de_sexed_age = ifelse(pet_de_sexed_age == "Not Sure", 
                                   sample(valid_values, sum(pet_de_sexed_age == "Not Sure"), replace = TRUE),
                                   pet_de_sexed_age))

# Filter out "Not Sure" values and get unique values from the pet_de_sexed_age column
valid_values <- earned$pet_de_sexed_age[earned$pet_de_sexed_age != "Not Sure"]

# Randomly replace "Not Sure" with any of the valid values
earned <- earned %>%
  mutate(pet_de_sexed_age = ifelse(pet_de_sexed_age == "Not Sure", 
                                   sample(valid_values, sum(pet_de_sexed_age == "Not Sure"), replace = TRUE),
                                   pet_de_sexed_age))

# Subset the data where 'pet_is_switcher' is not missing
non_missing_switcher <- earned[!is.na(earned$pet_is_switcher), ]

# Split the non-missing data into train and test sets (70% train, 30% test)
set.seed(123)  # For reproducibility
train_index <- createDataPartition(non_missing_switcher$pet_is_switcher, p = 0.7, list = FALSE)
train_data <- non_missing_switcher[train_index, ]
test_data <- non_missing_switcher[-train_index, ]

# Ensure 'pet_is_switcher' is a factor for classification
train_data$pet_is_switcher <- as.factor(train_data$pet_is_switcher)
test_data$pet_is_switcher <- as.factor(test_data$pet_is_switcher)

# Fit the random forest model on the training data
rf_model <- randomForest(pet_is_switcher ~ ., data = train_data, na.action = na.omit)

# Predict on the test set to evaluate model performance
test_predictions <- predict(rf_model, newdata = test_data)

# Create confusion matrix to evaluate model accuracy on the test set
conf_matrix <- confusionMatrix(test_predictions, test_data$pet_is_switcher)

# Print the confusion matrix to check accuracy and other metrics
print(conf_matrix)

# Now predict the missing values in 'predict_data' (rows where 'pet_is_switcher' is missing)
predict_data <- earned[is.na(earned$pet_is_switcher), ]
predict_data$pet_is_switcher <- predict(rf_model, newdata = predict_data)

# Combine the original datasets (train_data, test_data, and predict_data) back together
earned_unique <- rbind(train_data, test_data, predict_data)


#COMBINE CLAIMS AND EARNED DATA ----
# Perform a full join on the exposure_id
combined_data <- claims_data_new %>%
  full_join(earned_unique, by = "exposure_id")

# Ensure that columns from claims_data_new get NA values where there are no matches
combined_data <- combined_data %>%
  mutate(across(starts_with("column_prefix_claims"), ~ ifelse(is.na(.), NA, .)))

# If needed, you can arrange or select specific columns as well
# For example, rearranging or selecting only the columns you want to keep:
final_data <- combined_data %>%
  dplyr::select(exposure_id, everything())  # Adjust as necessary

# Replace NA values in the claim_status column
final_data <- final_data %>%
  dplyr::mutate(claim_status = ifelse(is.na(claim_status), "claim_not_made", claim_status))

#rename earned_units to exposure 
colnames(final_data)[33] = "exposure"

#change claim_count and claim_paid NAs to 0
final_data[is.na(claim_count) == T, claim_count := 0]
final_data[is.na(claim_paid) == T, claim_paid := 0]

#change pet_is_switcher NAs to FALSE
final_data[is.na(pet_is_switcher) == T, pet_is_switcher := "FALSE"]

#add pet age bins column 
final_data[, pet_age_months_bin := cut(pet_age_months, 
                                       c(1, 3, 8, 12, 16, 20, 24, 30, 35, 40, 50, 70, 100, 120), 
                                       labels = c("1-3", "4-8", "9-12", "13-16", "17-20", "21-24", "25-30", "31-35", "36-40", "41-50", "51-70", "71-100", "101-120"), 
                                       include.lowest = TRUE)]

final_data[, owner_age_years_bin := cut(owner_age_years, 
                                       c(18, 21, 25, 30, 35, 45, 55, 70, 90, 110), 
                                       labels = c("18-21", "22-25", "26-30", "31-35", "36-45", "46-55", "56-70", "71-90", "91-110"), 
                                       include.lowest = TRUE)]

#change columns to factors 
final_data[, `:=` (pet_de_sexed = as.factor(pet_de_sexed), 
                   pet_de_sexed_age = as.factor(pet_de_sexed_age), 
                   claim_status = as.factor(claim_status), 
                   nb_breed_type = as.factor(nb_breed_type), 
                   nb_breed_trait = as.factor(nb_breed_trait))]

#make NA values for owner_age_years the median
final_data[is.na(owner_age_years) == T, owner_age_years := median(owner_age_years)]

final_data <- final_data[, -c(10)]
print(final_data)
