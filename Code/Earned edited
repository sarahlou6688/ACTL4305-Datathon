#Load Packages
library(tidyverse)
library(lubridate)

#Import data
earned<- read.csv("UNSW_earned_data_adjusted_Sep27.csv")

#Dataset view
dim(earned)
summary(earned)

# Remove duplicate rows from 'earned' dataset
earned <- earned %>% distinct() #none detected

# Convert into correct data type
earned$pet_gender <- factor(earned$pet_gender)
earned$nb_address_type_adj <- factor(earned$nb_address_type_adj)
earned$nb_state <- factor(earned$nb_state)
earned$pet_de_sexed <- as.logical(earned$pet_de_sexed)
earned$pet_is_switcher <- as.logical(earned$pet_is_switcher)
earned$is_multi_pet_plan <- as.logical(earned$is_multi_pet_plan)

#UW_data make the month
# Assuming 'myrows' is your dataset and 'UW_date' is the column with dates
earned$UW_Date <- ymd_hms(earned$UW_Date)  # Convert the column to date-time format
# Extract the month name
earned$UW_Date_month <- month(earned$UW_Date, label = TRUE, abbr = FALSE)  # Extract full month name

# Convert 'nb_policy_first_inception_date' to date format without the time
earned$nb_policy_first_inception_date <- as_date(earned$nb_policy_first_inception_date)

# Remove specified columns from the 'earned' dataset
earned <- subset(earned, select = -c(quote_date, quote_time_group, lead_date_day, person_dob, pet_age_years, UW_Date, row_num, exposure_id_1))

#Check for NA values present in the dataset
na_summary_freq<-sapply(earned, function (x) sum(is.na(x)))
na_summary_freq

unique(earned$pet_is_switcher)
unique(earned$pet_de_sexed_age)

# Remove the 'tenure' column using subset
earned <- subset(earned, select = -tenure)

# Load the dplyr library
library(dplyr)

# Group by exposure_id and sum earned_units
earned_sum <- earned %>%
  group_by(exposure_id) %>%
  summarise(earned_units = sum(earned_units, na.rm = TRUE), .groups = "drop")

# Get the first occurrence of each exposure_id to keep other columns intact
earned_unique <- earned %>%
  distinct(exposure_id, .keep_all = TRUE)

# Remove the original earned_units column to avoid duplication
earned_unique <- earned_unique[, !(names(earned_unique) %in% "earned_units")]

# Join the summed earned_units with the unique dataset
earned <- left_join(earned_unique, earned_sum, by = "exposure_id")

# Display the first few rows to check the result
head(earned)

#Not Sure Cleaning
age_frequency <- explore1 %>%
  group_by(nb_breed_name_unique, pet_de_sexed_age) %>%
  summarise(frequency = n(), .groups = 'drop') %>%
  arrange(nb_breed_name_unique, pet_de_sexed_age)

print(age_frequency)


breed_mode <- age_frequency %>%
  group_by(nb_breed_name_unique) %>%
  slice_max(frequency, with_ties = FALSE)  # Keep the row with the highest frequency

# View the result
print(breed_mode)


#replace not sure wtih mode
earned <- earned %>%
  left_join(breed_mode, by = "nb_breed_name_unique", suffix = c("", "_mode"))

# Replace "Not Sure" with the mode from breed_mode
earned <- earned %>%
  mutate(pet_de_sexed_age = ifelse(pet_de_sexed_age == "Not Sure", 
                                   pet_de_sexed_age_mode,  # Use the mode from breed_mode
                                   pet_de_sexed_age))      # Keep the original value otherwise

# Drop the extra mode column if not needed
earned <- earned %>%
  select(-pet_de_sexed_age_mode)

#Randomise Values for not sure
set.seed(1060)
# Filter out "Not Sure" values and get unique values from the pet_de_sexed_age column
valid_values <- earned$pet_de_sexed_age[earned$pet_de_sexed_age != "Not Sure"]

# Randomly replace "Not Sure" with any of the valid values
earned <- earned %>%
  mutate(pet_de_sexed_age = ifelse(pet_de_sexed_age == "Not Sure", 
                                   sample(valid_values, sum(pet_de_sexed_age == "Not Sure"), replace = TRUE),
                                   pet_de_sexed_age))



# Filter out "Not Sure" values and get unique values from the pet_de_sexed_age column
valid_values <- explore1$pet_de_sexed_age[explore1$pet_de_sexed_age != "Not Sure"]

# Randomly replace "Not Sure" with any of the valid values
explore1 <- explore1 %>%
  mutate(pet_de_sexed_age = ifelse(pet_de_sexed_age == "Not Sure", 
                                   sample(valid_values, sum(pet_de_sexed_age == "Not Sure"), replace = TRUE),
                                   pet_de_sexed_age))

# Remove the 'tenure' column using subset
earned <- subset(earned, select = -tenure)


# Load necessary libraries
library(randomForest)
library(caret)

# Split the dataset into training and testing sets
set.seed(123) # Set seed for reproducibility
train_index <- sample(seq_len(nrow(train_data)), size = 0.8 * nrow(train_data))
train_set <- train_data[train_index, ]
test_set <- train_data[-train_index, ]

# Ensure pet_is_switcher is a factor for classification
train_set$pet_is_switcher <- as.factor(train_set$pet_is_switcher)
test_set$pet_is_switcher <- as.factor(test_set$pet_is_switcher)

# Fit the Random Forest model on the training set
rf_model <- randomForest(pet_is_switcher ~ ., data = train_set, na.action = na.omit)

# Predict on the test set
test_set$predicted <- predict(rf_model, newdata = test_set)

# Evaluate the model's accuracy
confusion_matrix <- confusionMatrix(test_set$predicted, test_set$pet_is_switcher)

# Print the confusion matrix and accuracy
print(confusion_matrix)

# Predict the missing values for pet_is_switcher in the original dataset
predict_data$pet_is_switcher <- predict(rf_model, newdata = predict_data)

# Combine the datasets
earned <- rbind(train_set, test_set, predict_data)

# Display the first few rows of the updated dataset
head(earned)



##IMPUTATION FOR pet_is_switcher### (not sure if we should look at calculations based on policy period and inception dates)

non_missing_switcher <- earned[!is.na(earned$pet_is_switcher), ]
print(head(non_missing_switcher))  # This will show the first few rows without missing values in pet_is_switcher.


library(randomForest)

# Train a Random Forest model using relevant features
train_data <- earned[!is.na(earned$pet_is_switcher), ]
predict_data <- earned[is.na(earned$pet_is_switcher), ]

# Ensure pet_is_switcher is a factor for classification
train_data$pet_is_switcher <- as.factor(train_data$pet_is_switcher)

# Fit the model
rf_model <- randomForest(pet_is_switcher ~ .,data = train_data, na.action = na.omit)

# Predict the missing values for pet_is_switcher
predict_data$pet_is_switcher <- predict(rf_model, newdata = predict_data)

# Combine the datasets
earned <- rbind(train_data, predict_data)

